{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project: Langchain rag 2.0**"
      ],
      "metadata": {
        "id": "eVeleIVlgr0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Install required libraries**\n",
        "These libraries help with text extraction, AI processing, and handling file uploads."
      ],
      "metadata": {
        "id": "U6nDhghtg0sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract pypdf2 langchain-pinecone langchain-google-genai pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5BdyUn9chWi",
        "outputId": "b8281196-c289-4456-c565-80795367c29f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain-pinecone\n",
            "  Downloading langchain_pinecone-0.2.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-5.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Collecting aiohttp<3.11,>=3.10 (from langchain-pinecone)\n",
            "  Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain-pinecone) (0.3.32)\n",
            "Collecting langchain-tests<0.4.0,>=0.3.7 (from langchain-pinecone)\n",
            "  Downloading langchain_tests-0.3.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from langchain-pinecone) (1.26.4)\n",
            "Collecting pinecone<6.0.0,>=5.4.0 (from langchain-pinecone)\n",
            "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.8.4)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.10.6)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2024.12.14)\n",
            "Collecting pinecone-plugin-inference<2.0.0,>=1.0.3 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_inference-1.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.18.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.25.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.26.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-pinecone) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-pinecone) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-pinecone) (0.3.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-pinecone) (9.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone) (0.28.1)\n",
            "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain-pinecone)\n",
            "  Downloading langchain_core-0.3.33-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: pytest<9,>=7 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone) (8.3.4)\n",
            "Collecting pytest-asyncio<1,>=0.20 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone)\n",
            "  Downloading pytest_asyncio-0.25.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pytest-socket<1,>=0.6.0 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone)\n",
            "  Downloading pytest_socket-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting syrupy<5,>=4 (from langchain-tests<0.4.0,>=0.3.7->langchain-pinecone)\n",
            "  Downloading syrupy-4.8.1-py3-none-any.whl.metadata (36 kB)\n",
            "INFO: pip is looking at multiple versions of pinecone to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pinecone<6.0.0,>=5.4.0 (from langchain-pinecone)\n",
            "  Downloading pinecone-5.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "  Downloading pinecone-5.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-5.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting pinecone-plugin-inference==1.0.2 (from pinecone-client)\n",
            "  Downloading pinecone_plugin_inference-1.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting pinecone-client\n",
            "  Downloading pinecone_client-4.1.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone<6.0.0,>=5.4.0->langchain-pinecone)\n",
            "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain-pinecone) (2.8.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<0.4.0,>=0.3.7->langchain-pinecone) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<0.4.0,>=0.3.7->langchain-pinecone) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<0.4.0,>=0.3.7->langchain-pinecone) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<0.4.0,>=0.3.7->langchain-pinecone) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-pinecone) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-pinecone) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-pinecone) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.29->langchain-pinecone) (0.23.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<0.4.0,>=0.3.7->langchain-pinecone) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<0.4.0,>=0.3.7->langchain-pinecone) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone<6.0.0,>=5.4.0->langchain-pinecone) (1.17.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.10->langchain-pinecone) (0.2.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.0->langchain-tests<0.4.0,>=0.3.7->langchain-pinecone) (1.3.1)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_pinecone-0.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading langchain_google_genai-2.0.9-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_client-4.1.2-py3-none-any.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.4/216.4 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading langchain_tests-0.3.10-py3-none-any.whl (37 kB)\n",
            "Downloading langchain_core-0.3.33-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
            "Downloading pytest_asyncio-0.25.3-py3-none-any.whl (19 kB)\n",
            "Downloading pytest_socket-0.7.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading syrupy-4.8.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, pytesseract, pypdf2, pinecone-plugin-interface, syrupy, pytest-socket, pytest-asyncio, pinecone-plugin-inference, pinecone-client, aiohttp, pinecone, langchain-core, langchain-tests, langchain-pinecone, langchain-google-genai\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.11\n",
            "    Uninstalling aiohttp-3.11.11:\n",
            "      Successfully uninstalled aiohttp-3.11.11\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.32\n",
            "    Uninstalling langchain-core-0.3.32:\n",
            "      Successfully uninstalled langchain-core-0.3.32\n",
            "Successfully installed aiohttp-3.10.11 filetype-1.2.0 langchain-core-0.3.33 langchain-google-genai-2.0.9 langchain-pinecone-0.2.2 langchain-tests-0.3.10 pinecone-5.4.2 pinecone-client-4.1.2 pinecone-plugin-inference-3.1.0 pinecone-plugin-interface-0.0.7 pypdf2-3.0.1 pytesseract-0.3.13 pytest-asyncio-0.25.3 pytest-socket-0.7.0 syrupy-4.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Import Necessary Libraries**"
      ],
      "metadata": {
        "id": "K_7jAQlgg_rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "import PyPDF2\n",
        "import io\n",
        "import os\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "from google.colab import userdata\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain_core.documents import Document\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from uuid import uuid4"
      ],
      "metadata": {
        "id": "54fQbPT9cj0-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Define functions to extract text from different file types**"
      ],
      "metadata": {
        "id": "vMt3qbzOiFTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_file):\n",
        "    text = \"\"\n",
        "    reader = PyPDF2.PdfReader(pdf_file)\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def extract_text_from_image(image_file):\n",
        "    image = Image.open(image_file)\n",
        "    text = pytesseract.image_to_string(image)\n",
        "    return text\n",
        "\n",
        "def process_uploaded_file():\n",
        "    uploaded = files.upload()\n",
        "    extracted_text = \"\"\n",
        "    for file_name in uploaded.keys():\n",
        "        if file_name.endswith('.pdf'):\n",
        "            with open(file_name, \"rb\") as f:\n",
        "                extracted_text = extract_text_from_pdf(f)\n",
        "        elif file_name.endswith(('.png', '.jpg', '.jpeg')):\n",
        "            extracted_text = extract_text_from_image(file_name)\n",
        "        else:\n",
        "            with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
        "                extracted_text = f.read()\n",
        "\n",
        "    print(\"Extracted Text:\")\n",
        "    print(extracted_text)\n",
        "    return extracted_text\n",
        "\n",
        "# Process uploaded file and extract questions\n",
        "extracted_text = process_uploaded_file()\n",
        "questions = extracted_text.split(\"\\n\")  # Split text into questions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "5tpGp7s7cu5I",
        "outputId": "7ff4546f-551b-471b-9744-645239c5d864"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8d8958c9-2f69-43d5-ae4e-5cf72dfd23b7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8d8958c9-2f69-43d5-ae4e-5cf72dfd23b7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving rag questions.txt to rag questions.txt\n",
            "Extracted Text:\n",
            "who dreamed creation of pakistan and when?\n",
            "how mohammad ali jinnah succeed?\n",
            "why mahatma gandhi come in the politics?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Initialize the RAG (Retrieval-Augmented Generation) system**"
      ],
      "metadata": {
        "id": "OMAmsJsqiPpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Get embeddings ready:** Sets up Google's tools for creating embeddings.\n",
        "* **Connect to Pinecone:** Links to the Pinecone database where information is stored.\n",
        "* **Prepare the AI:** Gets the ChatGoogleGenerativeAI model ready to provide answers."
      ],
      "metadata": {
        "id": "RwW-n-6dkdDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize RAG system components\n",
        "def initialize_rag_system():\n",
        "  # Set API keys using userdata.get\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY_2')\n",
        "\n",
        "    # Initialize embeddings\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "    # Initialize Pinecone\n",
        "    pc = Pinecone(api_key=userdata.get(\"PINECONEKEY2\")) # Make sure this is your actual Pinecone API key or retrieve it from userdata\n",
        "    index_name = \"new-rag-index\"\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "    vector_store = PineconeVectorStore(index=pc.Index(index_name), embedding=embeddings)\n",
        "\n",
        "    # Initialize LLM (Generative AI model)\n",
        "    llm = ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-1.5-flash\",\n",
        "        temperature=0,\n",
        "        max_tokens=None,\n",
        "        timeout=None,\n",
        "        max_retries=2,\n",
        "    )\n",
        "    return vector_store, llm"
      ],
      "metadata": {
        "id": "PGE47nMRb4Rg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Process each question and generate an answer using AI**"
      ],
      "metadata": {
        "id": "sgl5DzUIibUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   **Find similar information:** For each question, Pinecone is used to search for the 2 most similar pieces of information in the database.\n",
        "*   **Get the AI's response:** The question and the similar information found are given to the Gemini AI model. Gemini then uses this information to create an answer.\n",
        "*   **Show the results:** The original question and Gemini's answer are displayed in the output.\n",
        "*   **Get the questions:** The questions are read in from a \".txt\" file.\n",
        "*   **Set up the system:** The RAG system, which uses AI to answer questions, is prepared.\n",
        "*   **Process and show answers:** The system works through each question, finds answers, and shows them in the Colab notebook's output area."
      ],
      "metadata": {
        "id": "TUE6aKfVjkBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each question and print answers\n",
        "def process_questions(questions, vector_store, llm):\n",
        "    for query in questions:\n",
        "        print(f\"\\n**Question**: {query}\")\n",
        "        # Perform vector search\n",
        "        vector_results = vector_store.similarity_search(query, k=2)\n",
        "\n",
        "        # Generate the final answer using LLM\n",
        "        final_answer = llm.invoke(f\"ANSWER THE USER QUERY: {query}, Here are some references: {vector_results}\")\n",
        "        print(f\"**Answer**: {final_answer.content}\")\n",
        "\n",
        "# Main workflow\n",
        "if __name__ == \"__main__\":\n",
        "  # Load questions from the file\n",
        "    print(\"Questions loaded:\", questions)\n",
        "\n",
        "    # Initialize RAG system\n",
        "    vector_store, llm = initialize_rag_system()\n",
        "\n",
        "    # Process questions and display answers in Colab output\n",
        "    process_questions(questions, vector_store, llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jV54NzydRNX",
        "outputId": "b9d02c52-117c-4d7a-fca0-6f3faffdcf05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Questions loaded: ['who dreamed creation of pakistan and when?', 'how mohammad ali jinnah succeed?', 'why mahatma gandhi come in the politics?']\n",
            "\n",
            "**Question**: who dreamed creation of pakistan and when?\n",
            "**Answer**: The creation of Pakistan wasn't the dream of a single person, but rather a culmination of ideas and efforts from many individuals over a considerable period.  However, **Muhammad Ali Jinnah** is widely considered the most prominent figure in the movement for a separate Muslim state.  He articulated the vision and led the Muslim League's efforts to achieve it.\n",
            "\n",
            "While the specific \"dream\" evolved over time, the idea of a separate Muslim homeland gained significant momentum in the early to mid-20th century, culminating in the **Pakistan Resolution (Lahore Resolution) passed in 1940**.  This resolution is generally considered the formal articulation of the demand for a separate Muslim state, marking a key moment in the dream's realization.  Therefore, while Jinnah is the most prominent figure associated with the dream, the dream itself solidified around **1940**.\n",
            "\n",
            "**Question**: how mohammad ali jinnah succeed?\n",
            "**Answer**: Muhammad Ali Jinnah's success in achieving the creation of Pakistan is a complex issue with no single answer.  Several factors contributed:\n",
            "\n",
            "* **Effective Leadership and Political Strategy:** Jinnah was a charismatic and skilled orator, able to unite and mobilize a diverse Muslim population across British India. He strategically shifted the Muslim League's focus from minority rights within a united India to the demand for a separate Muslim state, capitalizing on existing religious and political divisions.  His unwavering commitment to the goal of Pakistan was crucial.\n",
            "\n",
            "* **Exploitation of Existing Grievances:**  Jinnah effectively channeled pre-existing anxieties and grievances among Muslims regarding their political representation and fears of Hindu dominance in a unified India.  He presented the creation of Pakistan as a solution to these concerns.\n",
            "\n",
            "* **The Changing Political Landscape:** The weakening of British power in India after World War II created an opportunity for the rise of nationalist movements.  The British, facing increasing pressure and internal instability, were ultimately willing to consider partition as a way to manage their withdrawal.\n",
            "\n",
            "* **The Role of the Indian National Congress:** While the Congress initially aimed for a unified India, its inability to fully address Muslim concerns and its own internal divisions inadvertently contributed to the success of the Muslim League's separatist agenda.  The failure of negotiations between the Congress and the Muslim League created a climate where partition seemed increasingly inevitable.\n",
            "\n",
            "* **International Context:** The global political climate following World War II, including the rise of nationalism and the decline of colonialism, provided a favorable environment for the creation of new nation-states.\n",
            "\n",
            "It's important to note that Jinnah's success was also controversial and came at a significant cost. The partition of India resulted in widespread violence, displacement, and loss of life.  His legacy remains a subject of intense debate and differing interpretations.  His success, therefore, should be viewed within the context of both its achievements and its devastating consequences.\n",
            "\n",
            "**Question**: why mahatma gandhi come in the politics?\n",
            "**Answer**: Mahatma Gandhi entered politics as a response to the injustices and discrimination faced by Indians under British colonial rule.  While he initially focused on legal and social reform, the increasingly oppressive policies and the lack of progress through existing channels pushed him towards active political resistance.  He believed in the power of nonviolent resistance (Satyagraha) to achieve self-rule and social justice for all Indians.  His involvement stemmed from a deep commitment to his country's independence and a belief in the moral imperative to fight for equality and freedom.\n"
          ]
        }
      ]
    }
  ]
}